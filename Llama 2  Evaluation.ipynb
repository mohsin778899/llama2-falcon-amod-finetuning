{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bad813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu118\n",
      "True\n",
      "NVIDIA RTX A4000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Check PyTorch version\n",
    "print(torch.cuda.is_available())  # Ensure CUDA is available\n",
    "print(torch.cuda.get_device_name(0))  # Display the GPU name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4807fa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 tensorboard\n",
    "\n",
    "import torch\n",
    "import accelerate\n",
    "import peft\n",
    "import bitsandbytes\n",
    "import transformers\n",
    "import trl\n",
    "import tensorboard\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fadc0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "dataset_name = \"Amod/mental_health_counseling_conversations\"\n",
    "\n",
    "# Function to format each row\n",
    "def format_row(example):\n",
    "    user_prompt = example['Context']  # Replace with your column names\n",
    "    model_answer = example['Response']\n",
    "    return f\"<s> [INST] {user_prompt} [/INST] {model_answer} </s>\"\n",
    "\n",
    "# Select the first 1,000 rows\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "subset = dataset.select(range(1000))\n",
    "subset = subset.map(lambda x: {'text': format_row(x)})\n",
    "\n",
    "\n",
    "# Apply the formatting function to each row\n",
    "formatted_data = [format_row(row) for row in subset]\n",
    "\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"Llama-2-7b-chat-finetune\"\n",
    "\n",
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 5\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = True\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 100\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f753a409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.63s/it]\n",
      "C:\\Users\\LAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\peft\\utils\\other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4390/4390 2:57:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.190700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.037200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.983100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.951100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.943500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.922900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.881700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.808200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.764400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.772100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.717600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.725500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.701500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.661700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.598900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.501600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.478500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.480800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.476800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.491100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.471300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.414700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.369900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.308400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.244600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.255700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.226700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.206200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.085600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>1.029300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>1.028500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4390, training_loss=1.503748187714666, metrics={'train_runtime': 10644.7955, 'train_samples_per_second': 1.65, 'train_steps_per_second': 0.412, 'total_flos': 1.1635501048233984e+17, 'train_loss': 1.503748187714666, 'epoch': 5.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (you can process it here)\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "# Function to format each row\n",
    "\n",
    "def format_row(example):\n",
    "    context = example['Context']\n",
    "    response = example['Response']\n",
    "    return f\"<s> [INST] {context} [/INST] {response} </s>\"\n",
    "\n",
    "# Apply the formatting function to each row and add a new 'text' column\n",
    "dataset = dataset.map(lambda x: {'text': format_row(x)})\n",
    "\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",  # Ensure this directory exists or create it\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=100,  # Adjust save_steps to save checkpoints periodically\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dca8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e734e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!C:/Users/LAB/AppData/Local/Programs/Git/cmd/git.exe clone https://github.com/AIPHES/emnlp19-moverscore.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0f1c4e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] I’ve been stuck in this cycle of negative thoughts about myself. It feels like I can’t break free, and every little mistake makes me feel even worse. How do I stop feeling so worthless all the time? [/INST] I'm sorry you've been feeling worthless. Everyone has mistakes. We all make mistakes. We all feel bad sometimes. We all think negative thoughts at times. We all feel worthless at times. But, we are not worthless. We are all very valuable. We all make mistakes. We all feel bad sometimes. We all think negative thoughts at times. But, we are not worthless. We are all very valuable.I'm glad you are trying to change your thoughts. Thoughts shape our experiences. If we have negative thoughts, we will have negative experiences. If we have positive thoughts, we will have positive experiences. Try to focus on your strengths and things that make you happy\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our next model\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "prompt = \"I’ve been stuck in this cycle of negative thoughts about myself. It feels like I can’t break free, and every little mistake makes me feel even worse. How do I stop feeling so worthless all the time?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526108cb",
   "metadata": {},
   "source": [
    "# Instrction prompting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "27c7d8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt: You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
      "    Query: \"I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter?\n",
      "\n",
      "Generated Response: [INST] You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
      "    Query: \"I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter? [/INST] Wow, this is a deep question. I think that the first step is to recognize that you are not alone in feeling this way. There are many people who feel worthless and disconnected from others. The second step is to find a way to connect with others. This could be anything from joining a club to volunteering. Finding a way to connect with others can help you to feel more motivated. I think that the next step would be to find a way to connect with yourself. I\n",
      "\n",
      "Reference Response: It’s important to remember that feelings of not belonging can stem from being in the wrong environment. Try exploring new hobbies or communities where you can meet people with similar interests. Building connections takes time, so be patient with yourself. Focus on your strengths and the things you enjoy doing, even if they feel small. Sometimes, feeling like you matter starts with giving yourself the care and kindness you deserve. Also, don’t hesitate to reach out to a counselor or therapist to help you navigate these emotions and find clarity.\n",
      "\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Prompt: I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter?\n",
      "\n",
      "Generated Response: [INST] I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter? [/INST] I'm sorry you feel disconnected. It's hard to stay motivated when you feel disconnected. I'm glad you wrote because I think a lot of people may be feeling similar disconnects. I'm not sure how old you are, but I wonder if you are trying to fit in with peer groups? I wonder if you are trying to fit in with adult groups? Maybe you are trying to fit in with family members? Maybe you want to find a group of people who share your interests? Maybe you want to find a group of people who are similar to you? Maybe you want to find a group of people who are different from you? Maybe you want to\n",
      "\n",
      "Reference Response: It’s important to remember that feelings of not belonging can stem from being in the wrong environment. Try exploring new hobbies or communities where you can meet people with similar interests. Building connections takes time, so be patient with yourself. Focus on your strengths and the things you enjoy doing, even if they feel small. Sometimes, feeling like you matter starts with giving yourself the care and kindness you deserve. Also, don’t hesitate to reach out to a counselor or therapist to help you navigate these emotions and find clarity.\n",
      "\n",
      "--------------------------------------------------\n",
      "Example 1 - Precision: 0.8445, Recall: 0.8654, F1: 0.8548\n",
      "\n",
      "Example 2 - Precision: 0.8329, Recall: 0.8523, F1: 0.8425\n",
      "\n",
      "Average Precision: 0.8387\n",
      "Average Recall: 0.8588\n",
      "Average F1 Score: 0.8486\n"
     ]
    }
   ],
   "source": [
    "validation_prompts = [\n",
    "    # Instruction prompt\n",
    "    \"\"\"You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
    "    Query: \"I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter?\"\"\"\n",
    "    ,\n",
    "    # Original prompt\n",
    "#   \"I often feel anxious in social situations and worry about being judged. How can I overcome this fear and build confidence?\",\n",
    "    \"I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter?\",\n",
    "#    \"I’ve been stuck in this cycle of negative thoughts about myself. It feels like I can’t break free, and every little mistake makes me feel even worse. How do I stop feeling so worthless all the time?\"\n",
    "        \n",
    "]\n",
    "\n",
    "# Generate predictions for both prompts\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200, temperature=0.7, top_p=0.9)\n",
    "\n",
    "generated_responses = []\n",
    "for prompt in validation_prompts:\n",
    "    result = pipe(f\"[INST] {prompt} [/INST]\")\n",
    "    generated_responses.append(result[0]['generated_text'])\n",
    "\n",
    "# Reference responses\n",
    "reference_responses = [\n",
    "#    \"To overcome social anxiety, start by practicing small interactions in safe environments. Gradually expose yourself to more challenging situations while focusing on positive outcomes. Mindfulness, deep breathing exercises, and seeking support from a therapist can also help build confidence.\",\n",
    "#    \"To overcome social anxiety, start by practicing small interactions in safe environments. Gradually expose yourself to more challenging situations while focusing on positive outcomes. Mindfulness, deep breathing exercises, and seeking support from a therapist can also help build confidence.\"\n",
    "    \"It’s important to remember that feelings of not belonging can stem from being in the wrong environment. Try exploring new hobbies or communities where you can meet people with similar interests. Building connections takes time, so be patient with yourself. Focus on your strengths and the things you enjoy doing, even if they feel small. Sometimes, feeling like you matter starts with giving yourself the care and kindness you deserve. Also, don’t hesitate to reach out to a counselor or therapist to help you navigate these emotions and find clarity.\",\n",
    "    \"It’s important to remember that feelings of not belonging can stem from being in the wrong environment. Try exploring new hobbies or communities where you can meet people with similar interests. Building connections takes time, so be patient with yourself. Focus on your strengths and the things you enjoy doing, even if they feel small. Sometimes, feeling like you matter starts with giving yourself the care and kindness you deserve. Also, don’t hesitate to reach out to a counselor or therapist to help you navigate these emotions and find clarity.\"\n",
    "#    \"Breaking the cycle of negative thoughts takes practice, but it’s absolutely possible. Start by challenging the thoughts—ask yourself if they’re true or if you’re being too hard on yourself. Writing down positive affirmations or things you like about yourself can also help shift your mindset. Practice self-compassion; treat yourself like you would a close friend. If you make a mistake, remind yourself it’s a natural part of learning. Therapy can also be a great resource to help you develop tools to combat these feelings and build your confidence.\"\n",
    "]\n",
    "\n",
    "for i, (prompt, gen_resp, ref_resp) in enumerate(zip(validation_prompts, generated_responses, reference_responses)):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Prompt: {prompt}\\n\")\n",
    "    print(f\"Generated Response: {gen_resp}\\n\")\n",
    "    print(f\"Reference Response: {ref_resp}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Compute BERTScore\n",
    "from bert_score import score\n",
    "P, R, F1 = score(generated_responses, reference_responses, lang='en')\n",
    "\n",
    "# Print the BERTScore for each prompt\n",
    "for i, (p, r, f1) in enumerate(zip(P, R, F1)):\n",
    "    print(f\"Example {i+1} - Precision: {p:.4f}, Recall: {r:.4f}, F1: {f1:.4f}\\n\")\n",
    "\n",
    "# Calculate and display average scores\n",
    "avg_precision = P.mean().item()\n",
    "avg_recall = R.mean().item()\n",
    "avg_f1 = F1.mean().item()\n",
    "\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c443dd",
   "metadata": {},
   "source": [
    "# 2nd Query Related to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ca0761dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt: You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
      "    Query: \"I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\n",
      "\n",
      "Generated Response: [INST] You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
      "    Query: \"I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone? [/INST] I'm glad you haven't taken any actions on your thoughts.  Your thoughts are not actions.  And your thoughts are not necessarily true.  The thoughts you write here are very common and typical of depression.  They are also not necessarily true.  Depression is very good at lying to people.  It tells us all kinds\n",
      "\n",
      "Reference Response: If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\n",
      "\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Prompt: I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\n",
      "\n",
      "Generated Response: [INST] I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone? [/INST] Check out my latest blog:  Four-ways-add-self-esteem,  I hope you find it helpful!  Let me know if you have any other questions.  ~Mark  (www.MarkMorrisLCSW.com and www.LivingYes.org)    (Facebook and Twitter links are in the bio section of my website)    (I use my professional website for professional and business purposes only.  My personal website, www.LivingYes.org,\n",
      "\n",
      "Reference Response: If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\n",
      "\n",
      "--------------------------------------------------\n",
      "Example 1 - Precision: 0.8293, Recall: 0.8337, F1: 0.8315\n",
      "\n",
      "Example 2 - Precision: 0.8113, Recall: 0.8277, F1: 0.8194\n",
      "\n",
      "Average Precision: 0.8203\n",
      "Average Recall: 0.8307\n",
      "Average F1 Score: 0.8255\n"
     ]
    }
   ],
   "source": [
    "validation_prompts = [\n",
    "    # Instruction prompt\n",
    "    \"\"\"You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
    "    Query: \"I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\"\"\"\n",
    "    ,\n",
    "    # Original prompt\n",
    "#   \"I often feel anxious in social situations and worry about being judged. How can I overcome this fear and build confidence?\",\n",
    "    \"I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\",\n",
    "#    \"I’ve been stuck in this cycle of negative thoughts about myself. It feels like I can’t break free, and every little mistake makes me feel even worse. How do I stop feeling so worthless all the time?\"\n",
    "        \n",
    "]\n",
    "\n",
    "# Generate predictions for both prompts\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200, temperature=0.7, top_p=0.9)\n",
    "\n",
    "generated_responses = []\n",
    "for prompt in validation_prompts:\n",
    "    result = pipe(f\"[INST] {prompt} [/INST]\")\n",
    "    generated_responses.append(result[0]['generated_text'])\n",
    "\n",
    "# Reference responses\n",
    "reference_responses = [\n",
    "    \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\",\n",
    "    \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\"\n",
    "]\n",
    "\n",
    "for i, (prompt, gen_resp, ref_resp) in enumerate(zip(validation_prompts, generated_responses, reference_responses)):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Prompt: {prompt}\\n\")\n",
    "    print(f\"Generated Response: {gen_resp}\\n\")\n",
    "    print(f\"Reference Response: {ref_resp}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Compute BERTScore\n",
    "from bert_score import score\n",
    "P, R, F1 = score(generated_responses, reference_responses, lang='en')\n",
    "\n",
    "# Print the BERTScore for each prompt\n",
    "for i, (p, r, f1) in enumerate(zip(P, R, F1)):\n",
    "    print(f\"Example {i+1} - Precision: {p:.4f}, Recall: {r:.4f}, F1: {f1:.4f}\\n\")\n",
    "\n",
    "# Calculate and display average scores\n",
    "avg_precision = P.mean().item()\n",
    "avg_recall = R.mean().item()\n",
    "avg_f1 = F1.mean().item()\n",
    "\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63f36a",
   "metadata": {},
   "source": [
    "# CoT Prompting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3812a3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to Original Prompt:\n",
      "I have been feeling more and more down for over a month. I have started having trouble sleeping due to panic attacks, but they are almost never triggered by something that I know of. I have been feeling very lonely and uncared for. I have been having trouble finding my purpose in life. I have been feeling more and more unmotivated. I have been having trouble staying on task and focusing. I have been having trouble eating and losing weight. I have been feeling very uncomfortable in my skin. I have been having trouble staying positive. I have been feeling very hopeless. I have been having trouble believing in a better future. I have been feeling very trapped. I have been having trouble seeing a way out. I have been feeling very scared. I have been having trouble trusting others. I have been having trouble trusting myself. I have been feeling very scared and unsure of what to do. I have been having trouble staying calm. I have been feeling very overwhelmed. I have been having trouble focusing on the present. I have been having trouble staying in the present. I have been feeling very disconnected from others\n",
      "\n",
      "Response to Improved Prompt:\n",
      "You are a compassionate mental health counselor having a private conversation with someone who feels worthless, struggles with their emotions, and finds it hard to take steps toward self-improvement. \n",
      "Craft a supportive and empathetic response that:\n",
      "1. Acknowledges and validates their feelings without judgment.\n",
      "2. Provides three small, actionable steps they can take immediately to start improving their self-esteem.\n",
      "3. Encourages them to recognize their strengths and reminds them of their intrinsic worth.\n",
      "4. Reassures them that their feelings are not permanent and can change with time and effort.\n",
      "5. Offers guidance on when and how to seek professional help for deeper support.\n",
      "\n",
      "Example response:\n",
      "I hear you, and I believe you. Feeling worthless is a common feeling for many people. It is hard to take steps toward self-improvement when you feel so low. I want to encourage you to start with small steps. First, take a walk around your neighborhood for 10 minutes. Second, write three things you are grateful for each day. Third, commit to spending 3\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt before adjustment\n",
    "before_prompt = \"I have been feeling more and more down for over a month. I have started having trouble sleeping due to panic attacks, but they are almost never triggered by something that I know of.\"\n",
    "\n",
    "# Define the improved prompt with explicit instructions\n",
    "after_prompt = \"\"\"You are a compassionate mental health counselor having a private conversation with someone who feels worthless, struggles with their emotions, and finds it hard to take steps toward self-improvement. \n",
    "Craft a supportive and empathetic response that:\n",
    "1. Acknowledges and validates their feelings without judgment.\n",
    "2. Provides three small, actionable steps they can take immediately to start improving their self-esteem.\n",
    "3. Encourages them to recognize their strengths and reminds them of their intrinsic worth.\n",
    "4. Reassures them that their feelings are not permanent and can change with time and effort.\n",
    "5. Offers guidance on when and how to seek professional help for deeper support.\n",
    "\"\"\"\n",
    "\n",
    "# Generate responses for both prompts\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=250)\n",
    "\n",
    "print(\"Response to Original Prompt:\")\n",
    "original_response = pipe(before_prompt)\n",
    "print(original_response[0]['generated_text'])\n",
    "\n",
    "print(\"\\nResponse to Improved Prompt:\")\n",
    "improved_response = pipe(after_prompt)\n",
    "print(improved_response[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9d8752e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 332.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.08 seconds, 12.48 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.05 seconds, 19.65 sentences/sec\n",
      "Original Response BERTScore:\n",
      "Precision: 0.7992, Recall: 0.7972, F1: 0.7982\n",
      "\n",
      "Improved Response BERTScore:\n",
      "Precision: 0.8495, Recall: 0.8081, F1: 0.8283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# References (ground truths) and Candidates\n",
    "references = [\n",
    "    \"Answers about our inner lives are most successfully reached from a sense of feeling grounded in oneself.First step is to accept your nervousness and restless sleep.  As often as possible, sleep during daytimes in order for your body to catch up on its need for rest.Accept too about feeling down.  It is normal to feel down once in a while.  From this place of self-acceptance, trust any answers which come up to your mind.  Often answers about complicated topics come in small pieces, not all at once as a whole unit.Also, your description about panic attacks is also completely normal.   They often arise unrelated to particular conditions at a given moment.  They are a healthy symptom your body is trying to expel bad feelings and does this by having the anxiety erupt at times.So, self-acceptance, tolerance of being on a process of clearing out worn out emotional clutter, and sleep at odd times if possible, are all ways to stabilize yourself, which will also feel calm and good!\",\n",
    "    \n",
    "]\n",
    "candidate_original = [\n",
    "    \" I have been feeling very lonely and uncared for. I have been having trouble finding my purpose in life. I have been feeling more and more unmotivated. I have been having trouble staying on task and focusing. I have been having trouble eating and losing weight. I have been feeling very uncomfortable in my skin. I have been having trouble staying positive. I have been feeling very hopeless. I have been having trouble believing in a better future. I have been feeling very trapped. I have been having trouble seeing a way out. I have been feeling very scared. I have been having trouble trusting others. I have been having trouble trusting myself. I have been feeling very scared and unsure of what to do. I have been having trouble staying calm. I have been feeling very overwhelmed. I have been having trouble focusing on the present. I have been having trouble staying in the present. I have been feeling very disconnected from others\"\n",
    "\n",
    "]\n",
    "candidate_improved = [\n",
    "    \"I hear you, and I believe you. Feeling worthless is a common feeling for many people. It is hard to take steps toward self-improvement when you feel so low. I want to encourage you to start with small steps. First, take a walk around your neighborhood for 10 minutes. Second, write three things you are grateful for each day. Third, commit to spending 3\"\n",
    "]\n",
    "\n",
    "# Calculate BERTScores\n",
    "P_original, R_original, F1_original = score(candidate_original, references, lang=\"en\", verbose=True)\n",
    "P_improved, R_improved, F1_improved = score(candidate_improved, references, lang=\"en\", verbose=True)\n",
    "\n",
    "print(\"Original Response BERTScore:\")\n",
    "print(f\"Precision: {P_original.mean():.4f}, Recall: {R_original.mean():.4f}, F1: {F1_original.mean():.4f}\")\n",
    "\n",
    "print(\"\\nImproved Response BERTScore:\")\n",
    "print(f\"Precision: {P_improved.mean():.4f}, Recall: {R_improved.mean():.4f}, F1: {F1_improved.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771280b",
   "metadata": {},
   "source": [
    "# Another Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6a6c4dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to Original Prompt:\n",
      "I'm going through things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone? [/INST] It sounds like you are feeling pretty overwhelmed and like you are not sleeping well. It's hard to know for sure without being there. But it sounds like you are struggling with some negative thoughts and you are not feeling like you are worth a lot to anyone. It sounds like you want to change this but you are not getting around to it. It sounds like you are not feeling like you are at your best right now. I would recommend reaching out to a friend or family member that you trust and talking with them about what you are going through. It can be really helpful to talk to someone about what you are going through. If you are not comfortable with that, I would recommend going to see a therapist. A therapist can help you to understand where these negative thoughts are coming\n",
      "\n",
      "Response to Improved Prompt:\n",
      "You are a compassionate mental health counselor having a private conversation with someone who feels worthless, struggles with their emotions, and finds it hard to take steps toward self-improvement. \n",
      "Craft a supportive and empathetic response that:\n",
      "1. Acknowledges and validates their feelings without judgment.\n",
      "2. Provides three small, actionable steps they can take immediately to start improving their self-esteem.\n",
      "3. Encourages them to recognize their strengths and reminds them of their intrinsic worth.\n",
      "4. Reassures them that their feelings are not permanent and can change with time and effort.\n",
      "5. Offers guidance on when and how to seek professional help for deeper support.\n",
      "\n",
      "Example response:\n",
      "I am so sorry to hear that you feel so low. I can tell that you are struggling with your emotions and finding it hard to take steps toward self-improvement. I am here to support you and I believe in you. I know that you are a strong person and you have many strengths. I also believe that your feelings are not permanent and you can change them with time and effort. I would\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt before adjustment\n",
    "before_prompt = \"I'm going through things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\"\n",
    "\n",
    "# Define the improved prompt with explicit instructions\n",
    "after_prompt = \"\"\"You are a compassionate mental health counselor having a private conversation with someone who feels worthless, struggles with their emotions, and finds it hard to take steps toward self-improvement. \n",
    "Craft a supportive and empathetic response that:\n",
    "1. Acknowledges and validates their feelings without judgment.\n",
    "2. Provides three small, actionable steps they can take immediately to start improving their self-esteem.\n",
    "3. Encourages them to recognize their strengths and reminds them of their intrinsic worth.\n",
    "4. Reassures them that their feelings are not permanent and can change with time and effort.\n",
    "5. Offers guidance on when and how to seek professional help for deeper support.\n",
    "\"\"\"\n",
    "\n",
    "# Generate responses for both prompts\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=250)\n",
    "\n",
    "print(\"Response to Original Prompt:\")\n",
    "original_response = pipe(before_prompt)\n",
    "print(original_response[0]['generated_text'])\n",
    "\n",
    "print(\"\\nResponse to Improved Prompt:\")\n",
    "improved_response = pipe(after_prompt)\n",
    "print(improved_response[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b2df2fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 234.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.06 seconds, 17.45 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 23.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.05 seconds, 18.92 sentences/sec\n",
      "Original Response BERTScore:\n",
      "Precision: 0.8385, Recall: 0.8280, F1: 0.8332\n",
      "\n",
      "Improved Response BERTScore:\n",
      "Precision: 0.8589, Recall: 0.8281, F1: 0.8432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# References (ground truths) and Candidates\n",
    "references = [\n",
    "    \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\",\n",
    "    \n",
    "]\n",
    "candidate_original = [\n",
    "    \" It sounds like you are feeling pretty overwhelmed and like you are not sleeping well. It's hard to know for sure without being there. But it sounds like you are struggling with some negative thoughts and you are not feeling like you are worth a lot to anyone. It sounds like you want to change this but you are not getting around to it. It sounds like you are not feeling like you are at your best right now. I would recommend reaching out to a friend or family member that you trust and talking with them about what you are going through. It can be really helpful to talk to someone about what you are going through. If you are not comfortable with that, I would recommend going to see a therapist. A therapist can help you to understand where these negative thoughts are coming\"\n",
    "]\n",
    "candidate_improved = [\n",
    "    \"I am so sorry to hear that you feel so low. I can tell that you are struggling with your emotions and finding it hard to take steps toward self-improvement. I am here to support you and I believe in you. I know that you are a strong person and you have many strengths. I also believe that your feelings are not permanent and you can change them with time and effort. I would\"\n",
    "]\n",
    "\n",
    "# Calculate BERTScores\n",
    "P_original, R_original, F1_original = score(candidate_original, references, lang=\"en\", verbose=True)\n",
    "P_improved, R_improved, F1_improved = score(candidate_improved, references, lang=\"en\", verbose=True)\n",
    "\n",
    "print(\"Original Response BERTScore:\")\n",
    "print(f\"Precision: {P_original.mean():.4f}, Recall: {R_original.mean():.4f}, F1: {F1_original.mean():.4f}\")\n",
    "\n",
    "print(\"\\nImproved Response BERTScore:\")\n",
    "print(f\"Precision: {P_improved.mean():.4f}, Recall: {R_improved.mean():.4f}, F1: {F1_improved.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a8c46",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
