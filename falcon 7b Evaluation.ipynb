{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4e6d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 tensorboard\n",
    "\n",
    "import torch\n",
    "import accelerate\n",
    "import peft\n",
    "import bitsandbytes\n",
    "import transformers\n",
    "import trl\n",
    "import tensorboard\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15599acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "dataset_name = \"Amod/mental_health_counseling_conversations\"\n",
    "\n",
    "# Function to format each row\n",
    "def format_row(example):\n",
    "    user_prompt = example['Context']  # Replace with your column names\n",
    "    model_answer = example['Response']\n",
    "    return f\"<s> [INST] {user_prompt} [/INST] {model_answer} </s>\"\n",
    "\n",
    "# Select the first 1,000 rows\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "subset = dataset.select(range(1000))\n",
    "subset = subset.map(lambda x: {'text': format_row(x)})\n",
    "\n",
    "\n",
    "# Apply the formatting function to each row\n",
    "formatted_data = [format_row(row) for row in subset]\n",
    "\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"Llama-2-7b-chat-finetune\"\n",
    "\n",
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 5\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = True\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 100\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7173f737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:12<00:00,  6.27s/it]\n",
      "C:\\Users\\LAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LAB\\AppData\\Roaming\\Python\\Python38\\site-packages\\peft\\utils\\other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\transformers\\models\\falcon\\modeling_falcon.py:341: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = F.scaled_dot_product_attention(\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4390/4390 2:38:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.328200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.286100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.208700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.991700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.959700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.962200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.934600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.926400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.867100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.788200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.773300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.764300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.790600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.769400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.710600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.588500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.595200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.583100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.584900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.560500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.475900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.457700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.432600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.503400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>1.430800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.431800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>1.457300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\LAB\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4390, training_loss=1.7963041509745605, metrics={'train_runtime': 9519.7818, 'train_samples_per_second': 1.845, 'train_steps_per_second': 0.461, 'total_flos': 1.0780729087872307e+17, 'train_loss': 1.7963041509745605, 'epoch': 5.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (you can process it here)\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "# Function to format each row\n",
    "\n",
    "def format_row(example):\n",
    "    context = example['Context']\n",
    "    response = example['Response']\n",
    "    return f\"<s> [INST] {context} [/INST] {response} </s>\"\n",
    "\n",
    "# Apply the formatting function to each row and add a new 'text' column\n",
    "dataset = dataset.map(lambda x: {'text': format_row(x)})\n",
    "\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    peft_type=\"LORA\",  # Type of PEFT method\n",
    "    task_type=\"CAUSAL_LM\",  # Task type (e.g., causal language modeling)\n",
    "    r=16,  # LoRA rank\n",
    "    lora_alpha=32,  # Alpha scaling factor\n",
    "    lora_dropout=0.1,  # Dropout probability\n",
    "    target_modules=[\"query_key_value\"]  # Specify target modules for Falcon\n",
    ")\n",
    "# Set training parameters\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",  # Ensure this directory exists or create it\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=100,  # Adjust save_steps to save checkpoints periodically\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e26afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f0ebbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone? [/INST] I'm sorry to hear that you're going through this.I'm glad you're not considering suicide. That's a good first step. I'm also glad you want to change your feelings of worthlessness. I'm not sure what you've tried so far, but I'm guessing you've tried talking to people you trust about how you feel. I'm also guessing you've tried reading books or articles about changing your feelings. I'm not sure what you've done, but I'm guessing\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, logging\n",
    "# Run text generation pipeline with our next model\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "prompt = \"I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd494a7f",
   "metadata": {},
   "source": [
    "# CoT Results on Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91d132ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to Original Prompt:\n",
      "I'm going through things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone? I feel it in every situation. I don't ever want to hurt anyone or anything.\n",
      "It sounds like you are going through a tough time and it's important to remember that you are not worthless. It's also important to take care of yourself and to seek help if you are feeling this way. Here are some things you can try:\n",
      "\n",
      "1. Practice self-care: This means taking care of your physical, emotional, and mental health. You can do this by eating healthy, exercising, getting enough sleep, and doing things that you enjoy.\n",
      "\n",
      "2. Change your thinking: It sounds like you have a lot of negative thoughts and beliefs about yourself. You can start by identifying these thoughts and challenging them. For example, if you think \"I'm worthless,\" ask yourself, \"What evidence do I have to support\n",
      "\n",
      "Response to Improved Prompt:\n",
      "You are a compassionate mental health counselor having a private conversation with someone who feels worthless, struggles with their emotions, and finds it hard to take steps toward self-improvement. \n",
      "Craft a supportive and empathetic response that:\n",
      "1. Acknowledges and validates their feelings without judgment.\n",
      "2. Provides three small, actionable steps they can take immediately to start improving their self-esteem.\n",
      "3. Encourages them to recognize their strengths and reminds them of their intrinsic worth.\n",
      "4. Reassures them that their feelings are not permanent and can change with time and effort.\n",
      "5. Offers guidance on when and how to seek professional help for deeper support.\n",
      "\n",
      "Example: 'I understand that you feel a bit down on yourself right now. It's important to remember that you are a wonderful person who has a lot to offer. When we feel this way, it can be helpful to acknowledge those feelings without judgment. I can see that you're trying to make some small changes in your life, and I applaud you for that. Remember, change takes time and effort, but you are absolutely worth it. Let's work together to create a plan for you to take three small steps toward self-improvement\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt before adjustment\n",
    "before_prompt = \"I'm going through things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\"\n",
    "\n",
    "# Define the improved prompt with explicit instructions\n",
    "after_prompt = \"\"\"You are a compassionate mental health counselor having a private conversation with someone who feels worthless, struggles with their emotions, and finds it hard to take steps toward self-improvement. \n",
    "Craft a supportive and empathetic response that:\n",
    "1. Acknowledges and validates their feelings without judgment.\n",
    "2. Provides three small, actionable steps they can take immediately to start improving their self-esteem.\n",
    "3. Encourages them to recognize their strengths and reminds them of their intrinsic worth.\n",
    "4. Reassures them that their feelings are not permanent and can change with time and effort.\n",
    "5. Offers guidance on when and how to seek professional help for deeper support.\n",
    "\"\"\"\n",
    "\n",
    "# Generate responses for both prompts\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=250)\n",
    "\n",
    "print(\"Response to Original Prompt:\")\n",
    "original_response = pipe(before_prompt)\n",
    "print(original_response[0]['generated_text'])\n",
    "\n",
    "print(\"\\nResponse to Improved Prompt:\")\n",
    "improved_response = pipe(after_prompt)\n",
    "print(improved_response[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3776b709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 249.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.06 seconds, 16.54 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 199.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.15 seconds, 6.49 sentences/sec\n",
      "Original Response BERTScore:\n",
      "Precision: 0.8412, Recall: 0.8335, F1: 0.8373\n",
      "\n",
      "Improved Response BERTScore:\n",
      "Precision: 0.8550, Recall: 0.8324, F1: 0.8435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# References (ground truths) and Candidates\n",
    "references = [\n",
    "    \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\",\n",
    "    \n",
    "]\n",
    "candidate_original = [\n",
    "    \"\"\" It sounds like you are going through a tough time and it's important to remember that you are not worthless. It's also important to take care of yourself and to seek help if you are feeling this way. Here are some things you can try:\n",
    "\n",
    "1. Practice self-care: This means taking care of your physical, emotional, and mental health. You can do this by eating healthy, exercising, getting enough sleep, and doing things that you enjoy.\n",
    "\n",
    "2. Change your thinking: It sounds like you have a lot of negative thoughts and beliefs about yourself. You can start by identifying these thoughts and challenging them. For example, if you think \"I'm worthless,\" ask yourself, \"What evidence do I have to support\"\"\"\n",
    "]\n",
    "candidate_improved = [\n",
    "    \"'I understand that you feel a bit down on yourself right now. It's important to remember that you are a wonderful person who has a lot to offer. When we feel this way, it can be helpful to acknowledge those feelings without judgment. I can see that you're trying to make some small changes in your life, and I applaud you for that. Remember, change takes time and effort, but you are absolutely worth it. Let's work together to create a plan for you to take three small steps toward self-improvement\"\n",
    "]\n",
    "\n",
    "# Calculate BERTScores\n",
    "P_original, R_original, F1_original = score(candidate_original, references, lang=\"en\", verbose=True)\n",
    "P_improved, R_improved, F1_improved = score(candidate_improved, references, lang=\"en\", verbose=True)\n",
    "\n",
    "print(\"Original Response BERTScore:\")\n",
    "print(f\"Precision: {P_original.mean():.4f}, Recall: {R_original.mean():.4f}, F1: {F1_original.mean():.4f}\")\n",
    "\n",
    "print(\"\\nImproved Response BERTScore:\")\n",
    "print(f\"Precision: {P_improved.mean():.4f}, Recall: {R_improved.mean():.4f}, F1: {F1_improved.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c295d",
   "metadata": {},
   "source": [
    "# Instruction Prompt Result on Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e58fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt: You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
      "    Query: \"I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\n",
      "\n",
      "Generated Response: [INST] You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
      "    Query: \"I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone? [/INST] Step 1: Acknowledge that you are worth something. \n",
      "Step 2: Create a list of 3 things that you are good at. \n",
      "Step 3: Share your list with someone you trust and ask them to give you feedback on your list. \n",
      "Step 4: Incorporate the feedback you receive into your daily life. \n",
      "Step 5: Celebrate your successes\n",
      "\n",
      "Reference Response: If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\n",
      "\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Prompt: I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\n",
      "\n",
      "Generated Response: [INST] I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone? [/INST] I'm sorry to hear that you're going through such a tough time. It sounds like you're going through a lot of emotional pain and you're feeling very overwhelmed. I'm glad that you're reaching out for help. I think it's great that you're ready to make some positive changes in your life. I'm not sure exactly what you mean by \"feelings of worthlessness,\" but I'm guessing that you feel like you're not good enough or that you're not worthy of being loved\n",
      "\n",
      "Reference Response: If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\n",
      "\n",
      "--------------------------------------------------\n",
      "Example 1 - Precision: 0.8262, Recall: 0.8358, F1: 0.8310\n",
      "\n",
      "Example 2 - Precision: 0.8294, Recall: 0.8255, F1: 0.8275\n",
      "\n",
      "Average Precision: 0.8278\n",
      "Average Recall: 0.8307\n",
      "Average F1 Score: 0.8292\n"
     ]
    }
   ],
   "source": [
    "validation_prompts = [\n",
    "    # Simplified CoT prompt\n",
    "    \"\"\"You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
    "    Query: \"I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\"\"\"\n",
    "    ,\n",
    "    # Original prompt\n",
    "#   \"I often feel anxious in social situations and worry about being judged. How can I overcome this fear and build confidence?\",\n",
    "    \"I'm going tsomehrough  things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\",\n",
    "#    \"I’ve been stuck in this cycle of negative thoughts about myself. It feels like I can’t break free, and every little mistake makes me feel even worse. How do I stop feeling so worthless all the time?\"\n",
    "        \n",
    "]\n",
    "\n",
    "# Generate predictions for both prompts\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200, temperature=0.7, top_p=0.9)\n",
    "\n",
    "generated_responses = []\n",
    "for prompt in validation_prompts:\n",
    "    result = pipe(f\"[INST] {prompt} [/INST]\")\n",
    "    generated_responses.append(result[0]['generated_text'])\n",
    "\n",
    "# Reference responses\n",
    "reference_responses = [\n",
    "#    \"To overcome social anxiety, start by practicing small interactions in safe environments. Gradually expose yourself to more challenging situations while focusing on positive outcomes. Mindfulness, deep breathing exercises, and seeking support from a therapist can also help build confidence.\",\n",
    "#    \"To overcome social anxiety, start by practicing small interactions in safe environments. Gradually expose yourself to more challenging situations while focusing on positive outcomes. Mindfulness, deep breathing exercises, and seeking support from a therapist can also help build confidence.\"\n",
    "    \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\",\n",
    "    \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\"\n",
    "#    \"Breaking the cycle of negative thoughts takes practice, but it’s absolutely possible. Start by challenging the thoughts—ask yourself if they’re true or if you’re being too hard on yourself. Writing down positive affirmations or things you like about yourself can also help shift your mindset. Practice self-compassion; treat yourself like you would a close friend. If you make a mistake, remind yourself it’s a natural part of learning. Therapy can also be a great resource to help you develop tools to combat these feelings and build your confidence.\"\n",
    "]\n",
    "\n",
    "for i, (prompt, gen_resp, ref_resp) in enumerate(zip(validation_prompts, generated_responses, reference_responses)):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Prompt: {prompt}\\n\")\n",
    "    print(f\"Generated Response: {gen_resp}\\n\")\n",
    "    print(f\"Reference Response: {ref_resp}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Compute BERTScore\n",
    "from bert_score import score\n",
    "P, R, F1 = score(generated_responses, reference_responses, lang='en')\n",
    "\n",
    "# Print the BERTScore for each prompt\n",
    "for i, (p, r, f1) in enumerate(zip(P, R, F1)):\n",
    "    print(f\"Example {i+1} - Precision: {p:.4f}, Recall: {r:.4f}, F1: {f1:.4f}\\n\")\n",
    "\n",
    "# Calculate and display average scores\n",
    "avg_precision = P.mean().item()\n",
    "avg_recall = R.mean().item()\n",
    "avg_f1 = F1.mean().item()\n",
    "\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3eae75",
   "metadata": {},
   "source": [
    "# Instruction Prompt Result on Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ed3f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt: You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
      "    Query: \"I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter?\n",
      "\n",
      "Generated Response: [INST] You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
      "    Query: \"I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter? [/INST] You can start by taking a few minutes to reflect on your strengths and accomplishments. Write them down. Then, think about what you can do to build on those strengths and accomplishments. It doesn't have to be anything big. It could be as simple as making your bed, or taking a walk around your neighborhood. Celebrate your accomplishments and try to focus on your strengths. I hope this helps! </s> \n",
      "What are some common triggers that cause you to feel worthless? </s> \n",
      "As a therapist, I would\n",
      "\n",
      "Reference Response: It’s important to remember that feelings of not belonging can stem from being in the wrong environment. Try exploring new hobbies or communities where you can meet people with similar interests. Building connections takes time, so be patient with yourself. Focus on your strengths and the things you enjoy doing, even if they feel small. Sometimes, feeling like you matter starts with giving yourself the care and kindness you deserve. Also, don’t hesitate to reach out to a counselor or therapist to help you navigate these emotions and find clarity.\n",
      "\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Prompt: I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter?\n",
      "\n",
      "Generated Response: [INST] I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter? [/INST] I'm sorry to hear that you feel disconnected.  It sounds like you are feeling a sense of disconnection from yourself, your environment, and your relationships.  It's important to remember that you have the power to change this.  You can start by taking a look at your thoughts and beliefs about yourself and your life.  What are you telling yourself that is contributing to this feeling of disconnection?  What are you telling yourself that is causing you to feel like you don't belong?  What are you telling yourself that is causing you to feel like you don't matter?  What are you telling yourself that is causing you to feel disconnected\n",
      "\n",
      "Reference Response: It’s important to remember that feelings of not belonging can stem from being in the wrong environment. Try exploring new hobbies or communities where you can meet people with similar interests. Building connections takes time, so be patient with yourself. Focus on your strengths and the things you enjoy doing, even if they feel small. Sometimes, feeling like you matter starts with giving yourself the care and kindness you deserve. Also, don’t hesitate to reach out to a counselor or therapist to help you navigate these emotions and find clarity.\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1 - Precision: 0.8393, Recall: 0.8652, F1: 0.8520\n",
      "\n",
      "Example 2 - Precision: 0.8364, Recall: 0.8642, F1: 0.8501\n",
      "\n",
      "Average Precision: 0.8379\n",
      "Average Recall: 0.8647\n",
      "Average F1 Score: 0.8511\n"
     ]
    }
   ],
   "source": [
    "validation_prompts = [\n",
    "    # Simplified CoT prompt\n",
    "    \"\"\"You are a therapist. Help someone struggling with feelings of worthlessness by giving them two simple steps to improve their emotional well-being.\n",
    "    Query: \"I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter?\"\"\",\n",
    "    # Original prompt\n",
    "#   \"I often feel anxious in social situations and worry about being judged. How can I overcome this fear and build confidence?\",\n",
    "    \"I feel like I don’t belong anywhere, and no matter what I do, I’m never good enough. It’s hard to stay motivated when I feel so disconnected from everyone. How can I find my place and feel like I matter?\",\n",
    "#    \"I’ve been stuck in this cycle of negative thoughts about myself. It feels like I can’t break free, and every little mistake makes me feel even worse. How do I stop feeling so worthless all the time?\"\n",
    "        \n",
    "]\n",
    "\n",
    "# Generate predictions for both prompts\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200, temperature=0.7, top_p=0.9)\n",
    "\n",
    "generated_responses = []\n",
    "for prompt in validation_prompts:\n",
    "    result = pipe(f\"[INST] {prompt} [/INST]\")\n",
    "    generated_responses.append(result[0]['generated_text'])\n",
    "\n",
    "# Reference responses\n",
    "reference_responses = [\n",
    "#    \"To overcome social anxiety, start by practicing small interactions in safe environments. Gradually expose yourself to more challenging situations while focusing on positive outcomes. Mindfulness, deep breathing exercises, and seeking support from a therapist can also help build confidence.\",\n",
    "#    \"To overcome social anxiety, start by practicing small interactions in safe environments. Gradually expose yourself to more challenging situations while focusing on positive outcomes. Mindfulness, deep breathing exercises, and seeking support from a therapist can also help build confidence.\"\n",
    "    \"It’s important to remember that feelings of not belonging can stem from being in the wrong environment. Try exploring new hobbies or communities where you can meet people with similar interests. Building connections takes time, so be patient with yourself. Focus on your strengths and the things you enjoy doing, even if they feel small. Sometimes, feeling like you matter starts with giving yourself the care and kindness you deserve. Also, don’t hesitate to reach out to a counselor or therapist to help you navigate these emotions and find clarity.\",\n",
    "    \"It’s important to remember that feelings of not belonging can stem from being in the wrong environment. Try exploring new hobbies or communities where you can meet people with similar interests. Building connections takes time, so be patient with yourself. Focus on your strengths and the things you enjoy doing, even if they feel small. Sometimes, feeling like you matter starts with giving yourself the care and kindness you deserve. Also, don’t hesitate to reach out to a counselor or therapist to help you navigate these emotions and find clarity.\"\n",
    "#    \"Breaking the cycle of negative thoughts takes practice, but it’s absolutely possible. Start by challenging the thoughts—ask yourself if they’re true or if you’re being too hard on yourself. Writing down positive affirmations or things you like about yourself can also help shift your mindset. Practice self-compassion; treat yourself like you would a close friend. If you make a mistake, remind yourself it’s a natural part of learning. Therapy can also be a great resource to help you develop tools to combat these feelings and build your confidence.\",\n",
    "#    \"Breaking the cycle of negative thoughts takes practice, but it’s absolutely possible. Start by challenging the thoughts—ask yourself if they’re true or if you’re being too hard on yourself. Writing down positive affirmations or things you like about yourself can also help shift your mindset. Practice self-compassion; treat yourself like you would a close friend. If you make a mistake, remind yourself it’s a natural part of learning. Therapy can also be a great resource to help you develop tools to combat these feelings and build your confidence.\"\n",
    "]\n",
    "\n",
    "for i, (prompt, gen_resp, ref_resp) in enumerate(zip(validation_prompts, generated_responses, reference_responses)):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Prompt: {prompt}\\n\")\n",
    "    print(f\"Generated Response: {gen_resp}\\n\")\n",
    "    print(f\"Reference Response: {ref_resp}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Compute BERTScore\n",
    "from bert_score import score\n",
    "P, R, F1 = score(generated_responses, reference_responses, lang='en')\n",
    "\n",
    "# Print the BERTScore for each prompt\n",
    "for i, (p, r, f1) in enumerate(zip(P, R, F1)):\n",
    "    print(f\"Example {i+1} - Precision: {p:.4f}, Recall: {r:.4f}, F1: {f1:.4f}\\n\")\n",
    "\n",
    "# Calculate and display average scores\n",
    "avg_precision = P.mean().item()\n",
    "avg_recall = R.mean().item()\n",
    "avg_f1 = F1.mean().item()\n",
    "\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
